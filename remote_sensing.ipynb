{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIsLHbNKHyeW"
   },
   "source": [
    "# Prepare Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg6U5O-3ZLSq",
    "outputId": "64ed6f82-f990-4ae2-b56c-47d5ba75f07b"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = \"1ExI4cImHyoFPL0anBBHePui5zhRWKQvj\"\n",
    "output_path = \"RS_images_2800.rar\"\n",
    "\n",
    "# Use gdown to download\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "\n",
    "!apt-get install unrar\n",
    "!unrar x RS_images_2800.rar -o+  # unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhm0IsdAZe4w",
    "outputId": "28156c39-2327-4b66-cf92-f6d516c139bb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/content/RS_images_2800\"\n",
    "print(os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTP7DD9xH3BX"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_BVYIvQaCaT"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "random.seed(410)\n",
    "\n",
    "dataset_path = \"./RS_images_2800\"\n",
    "\n",
    "# Split the dataset proportionally\n",
    "train_ratio = 0.7  # Training set\n",
    "valid_ratio = 0.15  # Validation set\n",
    "test_ratio = 0.15   # Test set\n",
    "\n",
    "# Read all categories\n",
    "categories = sorted(os.listdir(dataset_path))\n",
    "categories_cleaned = [\"\".join(c[1:]) for c in categories]\n",
    "class_mapping = {c: i for i, c in enumerate(categories_cleaned)}\n",
    "\n",
    "# Store\n",
    "dataset = {\"train\": [], \"valid\": [], \"test\": []}\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    images = [os.path.join(category_path, img) for img in os.listdir(category_path)]\n",
    "\n",
    "    # Random shuffle\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calculate partition index\n",
    "    total_count = len(images)\n",
    "    train_count = int(total_count * train_ratio)\n",
    "    valid_count = int(total_count * valid_ratio)\n",
    "\n",
    "    # Split\n",
    "    dataset[\"train\"].extend([(img, category[1:], class_mapping[category[1:]]) for img in images[:train_count]])\n",
    "    dataset[\"valid\"].extend([(img, category[1:], class_mapping[category[1:]]) for img in images[train_count:train_count + valid_count]])\n",
    "    dataset[\"test\"].extend([(img, category[1:], class_mapping[category[1:]]) for img in images[train_count + valid_count:]])\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df_train = pd.DataFrame(dataset[\"train\"], columns=[\"image\", \"class_name\", \"class_num\"])\n",
    "df_valid = pd.DataFrame(dataset[\"valid\"], columns=[\"image\", \"class_name\", \"class_num\"])\n",
    "df_test = pd.DataFrame(dataset[\"test\"], columns=[\"image\", \"class_name\", \"class_num\"])\n",
    "\n",
    "# Save\n",
    "df_train.to_csv(\"train_data.csv\", index=False)\n",
    "df_valid.to_csv(\"valid_data.csv\", index=False)\n",
    "df_test.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5pzfybgdzoV",
    "outputId": "b3523bce-1081-42e5-c5b5-ed7cdf0acfe2"
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "# print(df_train.shape)\n",
    "# print(df_valid.shape)\n",
    "# print(df_test.shape)\n",
    "# print(df_train['class_name'].value_counts())\n",
    "# print(df_valid['class_name'].value_counts())\n",
    "# print(df_test['class_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B83wWIF6f9mO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set global random seed\n",
    "seed = 410\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdU2g8Qbf9HU"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_valid = pd.read_csv(\"valid_data.csv\")\n",
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Data enhancement\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),\n",
    "    transforms.RandomRotation(30),    # Rotation\n",
    "    transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),   # Brightness change\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_test_transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name, class_num = self.dataframe.iloc[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, class_num\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = LoadDataset(df_train, transform=train_transform)\n",
    "valid_dataset = LoadDataset(df_valid, transform=valid_test_transform)\n",
    "test_dataset = LoadDataset(df_test, transform=valid_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTBYfaL1hzya"
   },
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b52ye19FhzNf"
   },
   "outputs": [],
   "source": [
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNBaseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 50 * 50, 256)  #400x400 input, after 3 MaxPool iterations, becomes 50x50\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "num_classes = len(df_train[\"class_num\"].unique())\n",
    "\n",
    "model = CNNBaseline(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZH5ZUKD1irMl",
    "outputId": "a924ed2f-bc24-4ef4-f178-2cca79f4a3fc"
   },
   "outputs": [],
   "source": [
    "# !pip install torchview\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "sample_input = torch.randn(1, 3, 400, 400).to(device)\n",
    "output = model(sample_input)\n",
    "\n",
    "make_dot(output, params=dict(model.named_parameters())).render(\"cnn_architecture\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koRgmRRziSGl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_results(train_losses, valid_losses, train_accs, valid_accs, model_name=\"Model\"):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Draw loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, valid_losses, label=\"Valid Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} - Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Draw accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, valid_accs, label=\"Valid Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name} - Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_training_results.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgE2FZShnlqY"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, device, num_epochs=30, learning_rate=0.0001, early_stop_patience=5, model_name=\"Model\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Early stopping\n",
    "    best_val_loss = float(\"inf\")\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Record Loss and Accuracy\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accs, valid_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss = running_val_loss / len(valid_loader)\n",
    "        val_acc = correct / total\n",
    "        valid_losses.append(val_loss)\n",
    "        valid_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Early stoping & Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
    "            print(\"Best model saved!\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= early_stop_patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    # plot loss and acc\n",
    "    plot_training_results(train_losses, valid_losses, train_accs, valid_accs, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d39jWFOkh_Ad",
    "outputId": "befdd0a7-e9fc-4e5f-aea6-687092db2db6"
   },
   "outputs": [],
   "source": [
    "train_model(model, train_loader, valid_loader, device, num_epochs=30, model_name=\"CNN Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "7Z1u0oLuj47E",
    "outputId": "9858a8ef-bc12-41cc-a691-3c7d604c595e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdVvj0aUi35B"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return accuracy, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTrN1LXbi4jo",
    "outputId": "6a685721-73ff-49c7-cf82-8698f8a9a81d"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "best_model = CNNBaseline(num_classes).to(device)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy, predictions, labels = evaluate_model(best_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "LTxO49jXi9GS",
    "outputId": "73ac48e0-77a9-4a70-e426-555fe00ee091"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{model_name} confusion matrix\")\n",
    "    plt.savefig(f\"{model_name}_confusion_matrix.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Draw confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, df_train[\"class_name\"].unique(), model_name=\"CNN Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHXrYIuTInah"
   },
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L45-R4elma7y"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load ResNet-50 pre trained model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze the first 140 layers (only train the last few layers)\n",
    "for param in list(model.parameters())[:140]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the fully connected layer of ResNet-50\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kNPR9dAtsRA2",
    "outputId": "5c370257-d426-4b39-dc11-ecefec92c62b"
   },
   "outputs": [],
   "source": [
    "make_dot(output, params=dict(model.named_parameters())).render(\"resnet50_architecture\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TODfHPt1m95w",
    "outputId": "7892b6e7-d15f-4d24-b082-da155d200362"
   },
   "outputs": [],
   "source": [
    "train_model(model, train_loader, valid_loader, device, num_epochs=30, model_name=\"ResNet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "yNM5Ev9vnBQ9",
    "outputId": "27badeaf-eba1-4dab-89b9-c1f93a6dd69c"
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_resnet_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "best_resnet_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "best_resnet_model.load_state_dict(torch.load(\"ResNet-50_best.pth\"))\n",
    "best_resnet_model.to(device)\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy, predictions, labels = evaluate_model(best_resnet_model, test_loader, device)\n",
    "\n",
    "# Deaw confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, df_train[\"class_name\"].unique(), model_name=\"ResNet-50\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR7_BHcHry0u"
   },
   "source": [
    "#Vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "45d738b6fc8b428693821cac84b8d812",
      "d660c28c6530489f99ee52016218132b",
      "598fba754a1347ab9a80cb7cff736920",
      "ac39106562ac4c84a2157aa7f0a5a7fa",
      "35b7b100157a43dda66dabc0a32eb006",
      "4bf5c6a0dfab47cfbfe9c7cb4f62dada",
      "7fdbfd52b489470dbd2b00e6f4310cdc",
      "8d8020f489c54d91a5068290e3df2824",
      "dc7d7d33f9514a9cb66636242044c61b",
      "13af596e58714f119f8c6e71ce8514c8",
      "a91f4084d9bd4d38867a4620a6bb872f"
     ]
    },
    "id": "35a22DRlr7o1",
    "outputId": "b311fc2a-e4b5-4caa-e65d-329851c43660"
   },
   "outputs": [],
   "source": [
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "\n",
    "# Load ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "# Load ViT model (without classification head)\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.vit.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)  # Extract features\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        return self.classifier(cls_token)\n",
    "\n",
    "# Initialize model\n",
    "model = ViTClassifier(num_classes=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QAM29GBav_x2",
    "outputId": "113d54fc-158f-4d07-f542-4356f3184790"
   },
   "outputs": [],
   "source": [
    "output = model(torch.randn(1, 3, 224, 224).to(device))\n",
    "make_dot(output, params=dict(model.named_parameters())).render(\"vit_architecture\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzfbvOPZ0DJg"
   },
   "outputs": [],
   "source": [
    "train_transform_vit = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Vit needs 224x224 input\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_test_transform_vit = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJjydAwav4uR"
   },
   "outputs": [],
   "source": [
    "class ViTDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_num = self.dataframe.iloc[idx][[\"image\", \"class_num\"]]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # Ensure the shape is (3, 224, 224)\n",
    "        if image.shape != (3, 224, 224):\n",
    "            print(f\"Shape mismatch: {image.shape} at index {idx}\")\n",
    "\n",
    "        # Convert class_num to PyTorch tensor\n",
    "        class_num = torch.tensor(class_num, dtype=torch.long)\n",
    "\n",
    "        return image, class_num\n",
    "\n",
    "\n",
    "train_dataset_vit = ViTDataset(df_train, transform=train_transform_vit)\n",
    "valid_dataset_vit = ViTDataset(df_valid, transform=valid_test_transform_vit)\n",
    "test_dataset_vit = ViTDataset(df_test, transform=valid_test_transform_vit)\n",
    "\n",
    "train_loader_vit = DataLoader(train_dataset_vit, batch_size=batch_size, shuffle=True)\n",
    "valid_loader_vit = DataLoader(valid_dataset_vit, batch_size=batch_size, shuffle=False)\n",
    "test_loader_vit = DataLoader(test_dataset_vit, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_nCSNCGZwDD2",
    "outputId": "0d647efe-0fda-4f45-f8e6-902286455feb"
   },
   "outputs": [],
   "source": [
    "train_model(model, train_loader_vit, valid_loader_vit, device, num_epochs=30, model_name=\"ViT-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "O3zb55SF0_AF",
    "outputId": "e1264eb3-0a44-4b3e-e0f1-ff918ff70153"
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_vit_model = ViTClassifier(num_classes=7).to(device)\n",
    "best_vit_model.load_state_dict(torch.load(\"ViT-Base_best.pth\"))\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy, predictions, labels = evaluate_model(best_vit_model, test_loader_vit, device)\n",
    "\n",
    "# Draw confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, df_train[\"class_name\"].unique(), model_name=\"ViT-Base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYpwBoAL1pLy"
   },
   "source": [
    "# SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvKJmkAwF-he"
   },
   "outputs": [],
   "source": [
    "contrastive_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(400, scale=(0.2, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_augmented_views(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    view1 = contrastive_transforms(img)\n",
    "    view2 = contrastive_transforms(img)\n",
    "    return view1, view2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5g_jrPv0LVeq"
   },
   "outputs": [],
   "source": [
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.image_paths = df[\"image\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img1, img2 = get_augmented_views(img_path)\n",
    "        return img1, img2\n",
    "\n",
    "train_dataset_sim = SimCLRDataset(df_train)\n",
    "train_loader_sim = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlMCQRKLG-rw",
    "outputId": "b5499ef9-2528-43a2-c611-17092248d972"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SimCLR, self).__init__()\n",
    "        base_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        # Remove ResNet-50 Classification layer\n",
    "        self.encoder = nn.Sequential(*list(base_model.children())[:-1])\n",
    "\n",
    "        # Projection Head\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).squeeze()\n",
    "        z = self.projector(h)\n",
    "        return z\n",
    "\n",
    "\n",
    "model = SimCLR().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQhVIRnoHGy8"
   },
   "outputs": [],
   "source": [
    "def nt_xent_loss(z1, z2, temperature=0.3):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    logits = torch.matmul(z1, z2.T) / temperature\n",
    "    labels = torch.arange(z1.shape[0]).cuda()\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjkcUatCHJGO",
    "outputId": "256f202e-ce27-4d2e-e5f7-7daf4f40b6b0"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import json\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Record time\n",
    "start_time = time.time()\n",
    "\n",
    "# Record training history\n",
    "history = {\"train_loss\": [], \"learning_rate\": []}\n",
    "\n",
    "\n",
    "scaler = GradScaler(device=\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "best_train_loss = float(\"inf\")\n",
    "patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    for img1, img2 in train_loader:\n",
    "        img1, img2 = img1.cuda(), img2.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            z1, z2 = model(img1), model(img2)\n",
    "            loss = nt_xent_loss(z1, z2)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        del img1, img2, z1, z2, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    history[\"train_loss\"].append(avg_train_loss)\n",
    "    history[\"learning_rate\"].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Compute training time\n",
    "    epoch_time = time.time() - epoch_start\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/30] | Train Loss: {avg_train_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f} | Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_train_loss < best_train_loss:\n",
    "        best_train_loss = avg_train_loss\n",
    "        torch.save(model.encoder.state_dict(), \"simclr_best_model.pth\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    # Early Stopping\n",
    "    if early_stop_counter >= patience:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbbK6GzEPAmy",
    "outputId": "bb7e1353-ef0b-4ef1-bd5f-72c5db05226d"
   },
   "outputs": [],
   "source": [
    "def balanced_sample(df, frac=0.5, random_state=410):\n",
    "    return df.groupby(\"class_name\", group_keys=False).apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n",
    "\n",
    "df_train_sample = balanced_sample(df_train)\n",
    "\n",
    "# Check\n",
    "print(df_train[\"class_name\"].value_counts())\n",
    "print(df_train_sample[\"class_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5MD3_7a3Apl"
   },
   "outputs": [],
   "source": [
    "train_dataset_full = LoadDataset(df_train, transform=train_transform)\n",
    "train_dataset_sample = LoadDataset(df_train_sample, transform=train_transform)\n",
    "valid_dataset = LoadDataset(df_valid, transform=valid_test_transform)\n",
    "test_dataset = LoadDataset(df_test, transform=valid_test_transform)\n",
    "\n",
    "train_loader_full = DataLoader(train_dataset_full, batch_size=batch_size, shuffle=True)\n",
    "train_loader_sample = DataLoader(train_dataset_sample, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ddk1oZaI6njv",
    "outputId": "4798793d-6f78-4672-f29e-9e9055e6ec43"
   },
   "outputs": [],
   "source": [
    "# Load ResNet-50 pre trained with SimCLR\n",
    "simclr_model = models.resnet50()\n",
    "num_features = simclr_model.fc.in_features\n",
    "simclr_model.fc = nn.Identity()  # Remove the projection head\n",
    "simclr_model.load_state_dict(torch.load(\"simclr_best_model.pth\"), strict=False)\n",
    "simclr_model = simclr_model.cuda()\n",
    "\n",
    "\n",
    "# Add classification head\n",
    "simclr_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "simclr_model = simclr_model.to(device)\n",
    "\n",
    "# Full training set\n",
    "train_model(simclr_model, train_loader_full, valid_loader, device, num_epochs=30, model_name=\"SimCLR-Finetune_100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "CjsK8hfU38He",
    "outputId": "ed6f71c4-7a5f-45f2-b85a-d8865358d33a"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_simclr_model = models.resnet50()\n",
    "best_simclr_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "best_simclr_model.load_state_dict(torch.load(\"SimCLR-Finetune_100%_best.pth\"))\n",
    "best_simclr_model.to(device)\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy, predictions, labels = evaluate_model(best_simclr_model, test_loader, device)\n",
    "\n",
    "# Draw confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, df_train[\"class_name\"].unique(), model_name=\"SimCLR-Finetune_100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VvJBqNGk5FUa",
    "outputId": "d6998ebf-1ede-4c63-97b8-3adcb8fec22b"
   },
   "outputs": [],
   "source": [
    "# Load ResNet-50 pre trained with SimCLR\n",
    "simclr_model = models.resnet50()\n",
    "num_features = simclr_model.fc.in_features\n",
    "simclr_model.fc = nn.Identity()  # Remove the projection head\n",
    "simclr_model.load_state_dict(torch.load(\"simclr_best_model.pth\"), strict=False)\n",
    "simclr_model = simclr_model.cuda()\n",
    "\n",
    "# Add classification head\n",
    "simclr_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "simclr_model = simclr_model.to(device)\n",
    "\n",
    "# Half of training set\n",
    "train_model(simclr_model, train_loader_sample, valid_loader, device, num_epochs=30, model_name=\"SimCLR-Finetune_50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "eGic9w7I38Jp",
    "outputId": "e45be0a5-2c16-4b4e-fb1a-333db7b30db4"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_simclr_model = models.resnet50()\n",
    "best_simclr_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "best_simclr_model.load_state_dict(torch.load(\"SimCLR-Finetune_50%_best.pth\"))\n",
    "best_simclr_model.to(device)\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy, predictions, labels = evaluate_model(best_simclr_model, test_loader, device)\n",
    "\n",
    "# Draw confusion matrix\n",
    "plot_confusion_matrix(labels, predictions, df_train[\"class_name\"].unique(), model_name=\"SimCLR-Finetune_50%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
